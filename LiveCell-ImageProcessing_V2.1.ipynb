{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b859eef1",
   "metadata": {},
   "source": [
    "# BioImage Timelapse Processor: Multi-Dimensional ND2 to MP4\n",
    "## Automated Visualization Pipeline for Live-Cell Imaging Data (XYZCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3b805",
   "metadata": {},
   "source": [
    "### Read Me\n",
    "This notebook automates the processing of raw Nikon ND2 microscopy files into presentation-ready video files. It is designed to handle multi-dimensional data containing Time (T), Z-stacks (Z), Multi-positions (S), and Channels (C).\n",
    "#### Key Features\n",
    "- Metadata Extraction: Automatically reads physical dimensions (x, y, z) and time intervals (t).\n",
    "- Z-Projection: Converts 3D stacks into 2D images using Maximum Intensity Projection (MIP).\n",
    "- Auto-Normalization: Applies percentile-based normalization to enhance contrast while ignoring hot pixels.\n",
    "- Custom Visualization: Applies user-defined colormaps (LUTs) to specific channels.\n",
    "- Automatic Annotation:\n",
    "    - Scale Bar: Draws a physical scale bar based on metadata pixel size.\n",
    "    - Timestamp: Calculates and stamps \"HH:MM\" on every frame based on acquisition intervals.\n",
    "- Export: Saves individual channels and merged overlays as .mp4 video files.\n",
    "- Batch Processing: Can process a single file or iterate through an entire directory.\n",
    "\n",
    "#### How to Use\n",
    "1. Input Data: Place your .nd2 files in a local directory.\n",
    "2. Configuration (Section 3): Update the WorkingDir path to your folder.\n",
    "3. Channel Mapping: Update the ChannelInfo dictionary to match your specific experiment (e.g., Channel 0 = \"DAPI\", Color = \"Blue\").\n",
    "4. Run: Execute all cells. The script will create a _Processed folder containing the output videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae8a92",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries & Defining Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from bioio import BioImage\n",
    "import bioio_nd2\n",
    "from bioio_imageio.writers import TimeseriesWriter\n",
    "import shutil\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.1 FILE HANDLING FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Function to create output directory\n",
    "# Logic: Takes the parent folder name, appends a suffix, creates the folder if it doesn't exist.\n",
    "def MakeDir(WorkingDir: Path, Suffix: str):\n",
    "    FolderName = WorkingDir.name\n",
    "    outdir = WorkingDir / f\"{FolderName}_{Suffix}\"\n",
    "    outdir.mkdir(exist_ok=True) # exist_ok=True prevents errors if folder already exists\n",
    "    print(f\"Output directory: {outdir}\")\n",
    "    return outdir\n",
    "\n",
    "# Function to create sub-directory\n",
    "# Logic: Creates a sub-directory within a given parent directory.\n",
    "def MakeSubDir(ParentDir: Path, SubDirName: str):\n",
    "    subdir = ParentDir / SubDirName\n",
    "    subdir.mkdir(exist_ok=True) # exist_ok=True prevents errors if folder already exists\n",
    "    print(f\"Sub-directory created: {subdir}\")\n",
    "    return subdir\n",
    "\n",
    "# Function to remove file extensions\n",
    "# Logic: Iterates through a known list of microscopy extensions and strips them to get the base filename.\n",
    "def rm_ext(FileName):\n",
    "    extensions = [\".ome.tiff\", \".ome.tif\", \".tiff\", \".tif\", \".nd2\", \".czi\", \".lif\", \".oir\"]\n",
    "    for ext in extensions:\n",
    "        if FileName.endswith(ext):\n",
    "            FileName = FileName.replace(ext, \"\")\n",
    "            break\n",
    "    return FileName\n",
    "\n",
    "# Function to make the file list to process\n",
    "# Logic: Handles \"DryRun\" (testing) and standard batch processing.\n",
    "def FileList(\n",
    "    WorkingDir: Path,\n",
    "    FileToProcess: str,\n",
    "    DryRun: bool\n",
    "):\n",
    "    # Dry Run: First image only\n",
    "    # Useful for testing parameters on a single file before running a large batch.\n",
    "    if DryRun == True: \n",
    "        ND2_File = next(WorkingDir.glob(\"*.nd2\"), None) # Next function to get the first & glob to find files matching pattern\n",
    "        if ND2_File is None:\n",
    "            print(\"No ND2 files found\")\n",
    "            return []\n",
    "        \n",
    "        print(\"Dry run enabled. Only processing the first ND2 file:\", ND2_File.name)\n",
    "        return [ND2_File]\n",
    "    # End of DryRun if block\n",
    "    \n",
    "    # Normal Run: Find all ND2 files\n",
    "    ND2_File = list(WorkingDir.glob(\"*.nd2\"))\n",
    "    # Error handling if no ND2 files found\n",
    "    if not ND2_File: \n",
    "        print(\"No ND2 files found\")\n",
    "        return []\n",
    "\n",
    "    # Process all ND2 files\n",
    "    if FileToProcess == \"all\":\n",
    "        print(f\"Processing all ND2 files in the directory. Total files found: {len(ND2_File)}\")\n",
    "        return ND2_File\n",
    "    # Process a specific ND2 file by name\n",
    "    for file in ND2_File:\n",
    "        if file.name == FileToProcess:\n",
    "            print(f\"Processing specific ND2 file: {FileToProcess}\")\n",
    "            return [file]\n",
    "    print(f\"Requested file not found: {FileToProcess}\")\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.2 ND2 PROCESSING FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Function to extract ND2 metadata\n",
    "# Logic: Uses bioio property accessors to get physical dimensions (microns) and time intervals.\n",
    "def ND2_Metadata(img):\n",
    "\n",
    "    std_md = img.standard_metadata\n",
    "    # Checking the timelapse metadata existence\n",
    "    if getattr(std_md, \"timelapse_interval\", None) is not None:\n",
    "        delta_time = round(std_md.timelapse_interval.total_seconds() / 60) * 60  # Rounded to nearest minute (in seconds)\n",
    "    else:\n",
    "        delta_time = None\n",
    "\n",
    "    if getattr(std_md, \"total_time_duration\", None) is not None:\n",
    "        duration_secs = std_md.total_time_duration.total_seconds()\n",
    "        duration_hrs = round(duration_secs / 3600)\n",
    "    else:\n",
    "        duration_secs = None\n",
    "        duration_hrs = None\n",
    "\n",
    "    n_frames = std_md.image_size_t\n",
    "    if n_frames is None or n_frames < 1: n_frames = 1\n",
    "    \n",
    "    # Extracting metadata into a clean dictionary\n",
    "    md = {\n",
    "        \"DimOrder\": std_md.dimensions_present,      # e.g., 'TCZYX'\n",
    "        \"nScenes\": len(img.scenes),                 # Number of XY positions\n",
    "        \"nFrames\": n_frames,             # Timepoints\n",
    "        \"nChannels\": std_md.image_size_c,           # Channels\n",
    "        \"nSlices\": std_md.image_size_z,             # Z-planes\n",
    "        \"nPixelsY\": std_md.image_size_y,            # Height\n",
    "        \"nPixelsX\": std_md.image_size_x,            # Width\n",
    "        \"xPixel_size_um\": std_md.pixel_size_x,      # Calibration X\n",
    "        \"yPixel_size_um\": std_md.pixel_size_y,      # Calibration Y\n",
    "        \"zPixel_size_um\": std_md.pixel_size_z,      # Calibration Z\n",
    "        \"deltaTime\": delta_time,\n",
    "        \"Duration_Secs\": duration_secs,\n",
    "        \"Duration_Hrs\": duration_hrs\n",
    "    }\n",
    "\n",
    "    # Printing metadata for user verification\n",
    "    print(\n",
    "        f\"Dimension Order: {md['DimOrder']}, \"\n",
    "        f\"Scenes: {md['nScenes']}, \"\n",
    "        f\"Frames: {md['nFrames']}, \"\n",
    "        f\"Channels: {md['nChannels']}, \"\n",
    "        f\"Slices(Z): {md['nSlices']}, \"\n",
    "        f\"Pixels(Y,X): ({md['nPixelsY']},{md['nPixelsX']})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Pixel Size: X={md['xPixel_size_um']} µm, \"\n",
    "        f\"Y={md['yPixel_size_um']} µm, \"\n",
    "        f\"Z={md['zPixel_size_um']} µm\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Frame Interval: {md['deltaTime']} s, \"\n",
    "        f\"Total Duration: {md['Duration_Secs']} s, \"\n",
    "        f\"Total Duration: {md['Duration_Hrs']} Hrs\"\n",
    "    )\n",
    "\n",
    "    return md\n",
    "\n",
    "# Function to make the scene list to process\n",
    "# Logic: Decides whether to process all scenes (XY positions) or a user-defined subset.\n",
    "def SceneList(\n",
    "    img,\n",
    "    ScenesToProcess: str | list[int],\n",
    "    DryRun: bool\n",
    "):\n",
    "    nScenes = len(img.scenes)\n",
    "\n",
    "    # Dry Run: First image only (Scene 0)\n",
    "    if DryRun == True: \n",
    "        print(\"Dry run enabled. Only processing the first scene: 0\")\n",
    "        return [0]\n",
    "    # End of DryRun if block\n",
    "    \n",
    "    # Normal Run\n",
    "    AllScenes = list(range(nScenes))\n",
    "    # Error handling if no scenes found\n",
    "    if nScenes == 0: \n",
    "        print(\"No scenes found\")\n",
    "        return []\n",
    "    # Process all scenes in the file\n",
    "    if ScenesToProcess == \"all\":\n",
    "        print(f\"Processing all scenes in the ND2 file. Total scenes found: {nScenes}\")\n",
    "        return AllScenes\n",
    "    \n",
    "    # Process a specific list of scenes provided by user\n",
    "    if isinstance(ScenesToProcess, list):\n",
    "\n",
    "        # Optional: validate indices to ensure they exist in the file\n",
    "        valid_scenes = [s for s in ScenesToProcess if 0 <= s < nScenes]\n",
    "        if not valid_scenes:\n",
    "            print(\"No valid scenes specified\")\n",
    "            return []\n",
    "        print(f\"Processing specific scenes: {valid_scenes}\")\n",
    "        return valid_scenes\n",
    "    print(\"Invalid value for ScenesToProcess\")\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.3 VISUALIZATION FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "# Function to get channel data with correct dimensionality\n",
    "# Logic: Depending on presence of T and Z axes, retrieves image data in appropriate shape.\n",
    "def get_channel_data(img, MD, channel_idx):\n",
    "    nFrames = int(MD.get(\"nFrames\") or 1)\n",
    "    nSlices = int(MD.get(\"nSlices\") or 1)\n",
    "\n",
    "    if nFrames > 1 and nSlices > 1: order = \"TZYX\"\n",
    "    elif nFrames == 1 and nSlices > 1: order = \"ZYX\"\n",
    "    elif nFrames > 1 and nSlices == 1: order = \"TYX\"\n",
    "    else: order = \"YX\"\n",
    "\n",
    "    cimg = img.get_image_data(order, C=channel_idx)\n",
    "    return cimg, order\n",
    "\n",
    "# Function to determine if the dataset is a timelapse\n",
    "# Logic: Checks for presence of Time axis, multiple frames, and non-zero deltaTime.\n",
    "def IsTimelapse(MD, cimg_dimorder):\n",
    "    nFrames = MD.get(\"nFrames\")\n",
    "    deltaTime = MD.get(\"deltaTime\")\n",
    "    has_Time_axis = 'T' in cimg_dimorder\n",
    "    has_nframes = nFrames is not None and nFrames > 1\n",
    "    has_deltaTime = deltaTime is not None and deltaTime > 0\n",
    "    return True if has_Time_axis and has_nframes and has_deltaTime else False\n",
    "\n",
    "# Defining projection function\n",
    "# Logic: Projects a 3D/4D stack along a specified axis using min, max, sum, mean, or standard deviation.\n",
    "def project(\n",
    "    stack: np.ndarray,\n",
    "    mode: str,\n",
    "    axis: str,\n",
    "    dim_order: str,\n",
    "    keepdims: bool\n",
    "):\n",
    "    if isinstance(axis, str): axis_idx = dim_order.index(axis) # Convert axis letter to index\n",
    "    \n",
    "    # Use float for safe arithmetic where needed\n",
    "    mode = mode.lower()\n",
    "    if mode in {\"sum\", \"mean\", \"sd\"}: data = stack.astype(np.float32)\n",
    "    else: data = stack\n",
    "\n",
    "    print(f\"Projecting {axis} axis, which is axis index {axis_idx}/{dim_order} in {mode} mode.\")\n",
    "\n",
    "    # Perform projection based on mode\n",
    "    if mode == \"min\": return np.min(data, axis=axis_idx, keepdims=keepdims)\n",
    "    elif mode == \"max\": return np.max(data, axis=axis_idx, keepdims=keepdims)\n",
    "    elif mode == \"sum\": return np.sum(data, axis=axis_idx, keepdims=keepdims)\n",
    "    elif mode == \"mean\": return np.mean(data, axis=axis_idx, keepdims=keepdims)\n",
    "    elif mode == \"sd\": return np.std(data, axis=axis_idx, keepdims=keepdims)\n",
    "    else: raise ValueError( \"Invalid mode. Choose one of: 'min', 'max', 'sum', 'mean', 'sd'\")\n",
    "\n",
    "# Defining normalization function (global or percentile based)\n",
    "# Logic: Normalizes image intensity to 0-1 range. Percentile helps ignore hot pixels/outliers.\n",
    "def norm_img(img, percent_norm=True, lower_pct=0.35, upper_pct=99.65): #percent_norm=True for percentile normalization\n",
    "    nFrame = img.shape[0]\n",
    "    mid_frame = nFrame // 2           # index for middle frame\n",
    "    ref_frame = img[mid_frame]   # reference frame used to calculate stats (assumed representative)\n",
    "\n",
    "    flat = ref_frame.flatten()\n",
    "    if percent_norm:\n",
    "        low = np.percentile(flat, lower_pct)\n",
    "        high = np.percentile(flat, upper_pct)\n",
    "    else:\n",
    "        low = flat.min()\n",
    "        high = flat.max()\n",
    "\n",
    "    denom = high - low if high != low else 1\n",
    "    normed = (img - low) / denom\n",
    "    normed_img = np.clip(normed, 0, 1) # Clips values outside the low/high range\n",
    "\n",
    "    print(\n",
    "    f\"Normalizing image using {'percentile, clipping ± ' + f'{100 - upper_pct:.2f}% values' if percent_norm else 'min–max'} method.\") \n",
    "    return normed_img\n",
    "\n",
    "# Defining colormaps\n",
    "# Logic: Generates a Matplotlib LinearSegmentedColormap (e.g., Black -> Green) and applies it to the image.\n",
    "def cmap(img, LUT: str, Isinverted: bool):\n",
    "    BaseColors = { # Dictionary of base colors\n",
    "        \"red\":     (1, 0, 0),\n",
    "        \"green\":   (0, 1, 0),\n",
    "        \"blue\":    (0, 0, 1),\n",
    "        \"yellow\":  (1, 1, 0),\n",
    "        \"magenta\": (1, 0, 1),\n",
    "        \"cyan\":    (0, 1, 1),\n",
    "        \"gray\":    (1, 1, 1),\n",
    "    }\n",
    "    assert LUT in BaseColors, f\"Invalid LUT name: {LUT}\"\n",
    "    color = BaseColors[LUT] # Calling the base color value\n",
    "    if Isinverted:\n",
    "        # White background to Color\n",
    "        img_cmap = LinearSegmentedColormap.from_list(f\"{LUT}_inv\", [color, (1, 1, 1)], N=256)\n",
    "    else:\n",
    "        # Black background to Color\n",
    "         img_cmap = LinearSegmentedColormap.from_list(LUT, [(0, 0, 0), color], N=256)\n",
    "    \n",
    "    # Apply LUT → RGB → uint8 conversion for standard video compatibility\n",
    "    img_rgb = img_cmap(img)[..., :3]\n",
    "    img_rgb_8bit = (img_rgb * 255).astype(np.uint8)\n",
    "    print(f\"Applying colormap: {LUT}\")\n",
    "    return img_rgb_8bit\n",
    "\n",
    "# Defining font size function\n",
    "# Logic: Calculates font size dynamically based on 6% of the image height.\n",
    "def font_size(img, scaling=0.06, min_size=10, max_size=48):\n",
    "    height = img.shape[0] # height of the image\n",
    "    font_size = int(height * scaling) # 6% of image height\n",
    "    font_size = max(min_size, min(max_size, font_size)) # Clamp between min and max\n",
    "    return font_size\n",
    "\n",
    "# Defining scale bar function\n",
    "# Logic: Draws a physical scale bar (e.g., 10um) on the image using PIL.\n",
    "def scale_bar(img, xPixel_size_um, color=(255, 255, 255), label=True):\n",
    "        \n",
    "    h, w = img.shape[:2] # height and width\n",
    "    max_len = w * xPixel_size_um * 0.2  # Target length approx 20% of image width\n",
    "    \n",
    "    # Picking suitable engineering series (1, 2, 5) to get a round number (e.g. 10, 20, 50 um)\n",
    "    exponent = int(math.floor(math.log10(max_len)))\n",
    "    candidates = [s * 10**exponent for s in [5, 2, 1]]\n",
    "    scale_bar_len_um = next((c for c in candidates if c <= max_len), max_len)\n",
    "\n",
    "    # Calculating scale bar dimensions in Pixels\n",
    "    scale_bar_px_length = int(round(scale_bar_len_um / xPixel_size_um)) # scale bar length in pixels\n",
    "    scale_bar_px_height = max(int(h * 0.01), 2) # scale bar height in pixels (1% of height)\n",
    "    \n",
    "    # Positioning scale bar at bottom-left corner\n",
    "    bar_x = w - int(w * 0.05) # 5% from side\n",
    "    bar_y = h - int(h * 0.035) # 3.5% from bottom\n",
    "\n",
    "    # Calculating bar coordinates for lower right\n",
    "    bar_x_end = bar_x\n",
    "    bar_x_start = bar_x_end - scale_bar_px_length\n",
    "\n",
    "    # Convert NumPy array to PIL Image for drawing\n",
    "    pil_img = Image.fromarray(img)\n",
    "\n",
    "    # Draw rectangle (scale bar) with PIL\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    draw.rectangle(\n",
    "        [(bar_x_start, bar_y), (bar_x_start + scale_bar_px_length, bar_y + scale_bar_px_height)],\n",
    "        fill=color)\n",
    "\n",
    "    # Convert back to NumPy array if needed\n",
    "    img_scaled = np.array(pil_img)\n",
    "\n",
    "    # Draw scale bar label (with PIL)\n",
    "    font_sz = font_size(img_scaled) # Calling the font size function\n",
    "    if label:\n",
    "        # Convert numpy image array to PIL Image\n",
    "        pil_img = Image.fromarray(img_scaled)\n",
    "        draw = ImageDraw.Draw(pil_img)\n",
    "        # Use a truetype font if available, or fallback to the default font\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", font_sz)\n",
    "        except Exception:\n",
    "            font = ImageFont.load_default()\n",
    "        label_text = f\"{scale_bar_len_um:g} µm\"  # Unicode micro symbol\n",
    "        \n",
    "        # Centering text above the scale bar\n",
    "        bbox = draw.textbbox((0,0), label_text, font=font)  # Retriving the bounding box of the text\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "        \n",
    "        # Calculating text position\n",
    "        bar_center = bar_x_start + ((bar_x_end - bar_x_start) // 2)\n",
    "        text_x = bar_center - (text_width // 2)\n",
    "        text_y = bar_y - 8 - text_height     # 8 pixel gap above scale bar\n",
    "\n",
    "        # Use a truetype font if available, or fallback to the default font\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", font_sz)\n",
    "        except Exception:\n",
    "            font = ImageFont.load_default()\n",
    "        \n",
    "        # Add the text to the image\n",
    "        draw.text((text_x, text_y), label_text, font=font, fill=color)\n",
    "        img_scaled = np.array(pil_img)\n",
    "\n",
    "    return img_scaled, scale_bar_len_um\n",
    "\n",
    "# Defining timestamp function\n",
    "# Logic: Calculates 'Hours:Minutes' based on frame index and deltaTime, draws text on Top-Left.\n",
    "def timestamp(img, frame_idx, deltaTime, color=(255, 255, 255)):\n",
    "    \n",
    "    font_sz = font_size(img) # Calling the font size function\n",
    "    # Convert numpy (OpenCV) image array to PIL Image\n",
    "    pil_img = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    # Use a truetype font if available, or fallback to the default font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_sz)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Calculate timestamp for this frame\n",
    "    Duration = frame_idx * deltaTime\n",
    "    hours = int(Duration // 3600)\n",
    "    minutes = int((Duration % 3600) // 60)\n",
    "    timestamp_str = f\"{hours:02d}:{minutes:02d} Hrs\"\n",
    "    \n",
    "    text_x, text_y = 10, 10 # Top left corner, with a small padding\n",
    "    draw.text((text_x, text_y), timestamp_str, font=font, fill=color)\n",
    "    img_timed = np.array(pil_img)\n",
    "    return img_timed\n",
    "\n",
    "# Defining annotation function for timelapse\n",
    "# Logic: Wrapper that iterates through a time-stack and applies scale_bar and timestamp to every frame.\n",
    "def annotate(\n",
    "    rgb_stack: np.ndarray,\n",
    "    xPixel_size_um: float,\n",
    "    deltaTime: float,\n",
    "    Add_Scalebar: bool,\n",
    "    Add_Timestamp: bool,\n",
    "    IsTimelapse: bool\n",
    "):\n",
    "    annotated_frames = []\n",
    "\n",
    "    for t in range(rgb_stack.shape[0]):\n",
    "        frame = rgb_stack[t].copy()  # IMPORTANT: avoid in-place modification\n",
    "\n",
    "        if Add_Scalebar:\n",
    "            frame, scale_bar_len_um = scale_bar(frame, xPixel_size_um)\n",
    "            \n",
    "        if Add_Timestamp and IsTimelapse:\n",
    "            frame = timestamp(frame, t, deltaTime) # Here t is the frame index\n",
    "\n",
    "        annotated_frames.append(frame)\n",
    "    print(f\"Adding Scale bar of {scale_bar_len_um:g} µm with label.\")\n",
    "    print(f\"Adding Timestamp.\")\n",
    "\n",
    "    return np.stack(annotated_frames, axis=0)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2.4 VIDEO SAVING FUNCTION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Function to pad frames to be multiples of block size\n",
    "# Logic: Pads the image stack with zeros to ensure width and height are multiples of 'block' (e.g., 16 for H.264).\n",
    "def framesize_pad(\n",
    "    img: np.ndarray,\n",
    "    order: str,\n",
    "    block: int = 16 #Imageio ffmeg_writer: macro_block_size=16, i.e., width and height must be multiples of 16\n",
    "):\n",
    "    # Identify Y and X axes from dimension order\n",
    "    y_axis = order.index('Y')\n",
    "    x_axis = order.index('X')\n",
    "\n",
    "    h = img.shape[y_axis]\n",
    "    w = img.shape[x_axis]\n",
    "\n",
    "    # Compute padded sizes (round up to nearest multiple of block)\n",
    "    new_h = ((h + block - 1) // block) * block\n",
    "    new_w = ((w + block - 1) // block) * block\n",
    "\n",
    "    pad_h = new_h - h\n",
    "    pad_w = new_w - w\n",
    "\n",
    "    # Initialize pad_width with no padding on all axes\n",
    "    pad_width = [(0, 0)] * img.ndim\n",
    "\n",
    "    # Apply padding only on Y and X axes\n",
    "    pad_width[y_axis] = (0, pad_h)\n",
    "    pad_width[x_axis] = (0, pad_w)\n",
    "\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        print(\n",
    "            f\"Padding adjustment for video encoding: \"\n",
    "            f\"Original Size=({w}x{h}), \"\n",
    "            f\"Padded Size=({new_w}x{new_h})\"\n",
    "        )\n",
    "    # Apply padding\n",
    "    padded = np.pad(img, pad_width, mode=\"constant\", constant_values=0)\n",
    "    return padded\n",
    "\n",
    "# Function to export MP4 video\n",
    "# Logic: Uses bioio_imageio to save the numpy stack as an MP4 file.\n",
    "def MP4_Export(\n",
    "    rgb_stack: np.ndarray,\n",
    "    output_dir: str | Path,\n",
    "    file_name: str,\n",
    "    scene_idx: int,\n",
    "    channel_idx: int | None,\n",
    "    fps: int,\n",
    "    verbose=True\n",
    "):\n",
    "\n",
    "    # Naming convention based on channel index\n",
    "    if channel_idx is None:\n",
    "        channel_tag = \"C0\"  # merged\n",
    "        label = \"Merged\"\n",
    "    else:\n",
    "        channel_tag = f\"C{channel_idx + 1}\" # e.g., Index 0 becomes C1\n",
    "        label = f\"Channel {channel_idx + 1}\"\n",
    "\n",
    "    output_video_path = (Path(output_dir) / f\"{file_name}_S{scene_idx + 1}_{channel_tag}.mp4\")\n",
    "    \n",
    "    # Save video using ffmpeg wrapper\n",
    "    TimeseriesWriter.save(\n",
    "        rgb_stack,\n",
    "        output_video_path,\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        quality=10\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Scene {scene_idx + 1}, {label} video saved at: \"\n",
    "            f\"{output_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb87c0f",
   "metadata": {},
   "source": [
    "### 2. User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b40f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Directory\n",
    "WorkingDir = Path(r\"D:\\02_VSI Working Directory\\UnderProcessing\\20250714_D161-iMyoD-PB24-D5_BFP-ftRLC-LfAct-6SWT_Lv-01Hr\") # CHANGE THIS PATH TO YOUR DATA DIRECTORY\n",
    "\n",
    "# User configurations\n",
    "FileToProcess = \"all\"               # \"all\" or filename\n",
    "ScenesToProcess = \"all\"             # \"all\" or specific list [0, 1, 2]\n",
    "Proj_mode = \"max\"                      # max, in mean, sum, min, sd (Projection method)\n",
    "Proj_axis = \"Z\"                   # Axis to project (z or T)\n",
    "FPS = 5                            # output video frames per second\n",
    "Add_Scalebar = True                 # whether to add scalebar\n",
    "Add_Timestamp = True                # whether to add timestamp\n",
    "\n",
    "# Channel information\n",
    "# Channel index (0–3), matching the acquisition order in the imaging file\n",
    "# Maps index to Name and Color for visualization\n",
    "ChannelInfo = { \n",
    "    0: {\"Name\": \"NLS-BFP\",   \"cmap\": \"yellow\"},\n",
    "    1: {\"Name\": \"ftRLC-mSG\", \"cmap\": \"magenta\"},\n",
    "    2: {\"Name\": \"LfAct-mSc3\",    \"cmap\": \"green\"},\n",
    "    3: {\"Name\": \"m6SWT-Halo7\",      \"cmap\": \"cyan\"},\n",
    "}\n",
    "\n",
    "# For Debugging\n",
    "DryRun = False                       # if True, only the first scene of the first image will be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7172be",
   "metadata": {},
   "source": [
    "### 3. Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "OutputDir = MakeDir(WorkingDir, Suffix=\"Video\") \n",
    "print(\"Output Directory:\", OutputDir)\n",
    "# Get list of files to process based on config\n",
    "FilesToProcess = FileList(WorkingDir, FileToProcess, DryRun) \n",
    "\n",
    "# --- LOOP THROUGH FILES ---\n",
    "for file in FilesToProcess: \n",
    "    print(\"Processing file:\", file)\n",
    "\n",
    "    FileName = rm_ext(file.name) # Remove file extension\n",
    "    print(\"File name without extension:\", FileName)\n",
    "\n",
    "    # Make sub-directory for each file\n",
    "    FileOutputDir = MakeSubDir(OutputDir, FileName)\n",
    "\n",
    "    img = BioImage(file, reader=bioio_nd2.Reader)   # Load ND2 image using BioImage\n",
    "\n",
    "    # Extract and print metadata\n",
    "    MD = ND2_Metadata(img)\n",
    "\n",
    "    # --- LOOP THROUGH SCENES (Positions) ---\n",
    "    for s in SceneList(img, ScenesToProcess, DryRun):  # Get list of scenes to process\n",
    "        print(f\"Processing scene: {int(s)+1}\")\n",
    "        \n",
    "        # Set scene (lazy loading specific scene)\n",
    "        img.set_scene(s)\n",
    "\n",
    "        cimg_list = []  # List to store individual processed channels for later merging\n",
    "\n",
    "        # --- LOOP THROUGH CHANNELS ---\n",
    "        for j in range(MD[\"nChannels\"]):\n",
    "            # Get image data for the current channel\n",
    "            cimg, order = get_channel_data(img, MD, channel_idx=j)\n",
    "\n",
    "            cimg = framesize_pad(cimg, order)  # Padding frames to be multiples of block size for video encoding\n",
    "            \n",
    "            print(f\"Processing Channel {j+1}/{MD['nChannels']}\")\n",
    "            print(f\"{order} with shape: {cimg.shape}\")\n",
    "\n",
    "            # Determine if the dataset is a timelapse\n",
    "            IsTimelapse_flag = IsTimelapse(MD, order)\n",
    "\n",
    "            if cimg.ndim > 3:\n",
    "                # Performing Projection\n",
    "                cimg_proj = project(\n",
    "                    stack=cimg,\n",
    "                    mode=Proj_mode,\n",
    "                    axis=Proj_axis,\n",
    "                    dim_order=order,\n",
    "                    keepdims=False\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Skipping projection due to unsupported dimensionality: {cimg.shape}\")\n",
    "                cimg_proj = cimg  # No projection applied\n",
    "\n",
    "            print(f\"Projected shape: {cimg_proj.shape}\")\n",
    "\n",
    "            # Percentile normalization (scales intensities 0.0 to 1.0)\n",
    "            cimg_mip_norm = norm_img(cimg_proj, percent_norm=True)\n",
    "\n",
    "            # Applying cmap (LUT) for visualization -> Converts to RGB\n",
    "            cmap_cimg_mip_norm = cmap(img=cimg_mip_norm, LUT=ChannelInfo[j][\"cmap\"], Isinverted=False)\n",
    "\n",
    "            print(f\"Colormapped shape: {cmap_cimg_mip_norm.shape}\")\n",
    "\n",
    "            # Annotating frames with scalebar and timestamp\n",
    "            cimg_mip_rgb_labeled = annotate(\n",
    "                rgb_stack=cmap_cimg_mip_norm,\n",
    "                xPixel_size_um=MD[\"xPixel_size_um\"],\n",
    "                deltaTime=MD[\"deltaTime\"],\n",
    "                Add_Scalebar=Add_Scalebar,\n",
    "                Add_Timestamp=Add_Timestamp,\n",
    "                IsTimelapse=IsTimelapse_flag)\n",
    "\n",
    "            # Save individual channel as MP4\n",
    "            MP4_Export(\n",
    "                rgb_stack=cimg_mip_rgb_labeled,\n",
    "                output_dir=FileOutputDir,\n",
    "                file_name=FileName,\n",
    "                scene_idx=int(s),\n",
    "                channel_idx=j,\n",
    "                fps=FPS,\n",
    "                verbose=True)\n",
    "\n",
    "            # Updating the cimg_list for the merged view\n",
    "            cimg_list.append(cmap_cimg_mip_norm.astype(np.float32)) # Converting to float32 for accurate summation in merge channel\n",
    "\n",
    "        # --- MERGE CHANNELS ---\n",
    "        # Summing channel intensities and clipping to valid 8-bit range (0-255)\n",
    "        merged_rgb = np.clip(sum(cimg_list), 0, 255).astype(np.uint8) # shape: [T, C, Y, X]\n",
    "\n",
    "        print(f\"Merged RGB shape: {merged_rgb.shape}\")\n",
    "\n",
    "        # Adding scale bar/timestamp to the Merged Stack\n",
    "        merged_mip_rgb_8bit_labeled = annotate(\n",
    "            rgb_stack=merged_rgb,\n",
    "            xPixel_size_um=MD[\"xPixel_size_um\"],\n",
    "            deltaTime=MD[\"deltaTime\"],\n",
    "            Add_Scalebar=Add_Scalebar,\n",
    "            Add_Timestamp=Add_Timestamp,\n",
    "            IsTimelapse=IsTimelapse_flag)\n",
    "\n",
    "        # Save Merged Stack as MP4 (Channel index None indicates 'Merged')\n",
    "        MP4_Export(\n",
    "            rgb_stack=merged_mip_rgb_8bit_labeled,\n",
    "            output_dir=FileOutputDir,\n",
    "            file_name=FileName,\n",
    "            scene_idx=int(s),\n",
    "            channel_idx=None,  \n",
    "            fps=FPS,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f85969",
   "metadata": {},
   "source": [
    "### 4. Appendix - Renaming Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb767dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the videos for ppt presentation\n",
    "# Logic: Generates sequential names (Video-1, Video-2...) to preserve order in slides/folder views.\n",
    "\n",
    "nChannels = int(MD[\"nChannels\"])\n",
    "\n",
    "print(\"OutputDir:\", OutputDir)\n",
    "OutputDir_Renamed = MakeDir(WorkingDir, Suffix=\"Video-Renamed\")\n",
    "\n",
    "# Iterate through each subfolder inside OutputDir\n",
    "for subdir in sorted([d for d in OutputDir.iterdir() if d.is_dir()]):\n",
    "    print(f\"\\nProcessing folder: {subdir.name}\")\n",
    "\n",
    "    OutputSubDir = MakeSubDir(OutputDir_Renamed, subdir.name)\n",
    "\n",
    "    FilePrefix = subdir.name\n",
    "\n",
    "    nFiles = sum(1 for f in subdir.iterdir() if f.is_file())\n",
    "    print(f\"Number of files in {subdir.name}: {nFiles}\")\n",
    "    nSeries = nFiles // (nChannels + 1)  # +1 for merged channel\n",
    "\n",
    "    counter = 1  # reset counter per subfolder\n",
    "\n",
    "    if DryRun:\n",
    "        print(\"Dry run enabled. No files will be renamed.\")\n",
    "        continue\n",
    "\n",
    "    # Iterate through Scenes (1 to N)\n",
    "    for s in range(1, nSeries + 1):\n",
    "        # Iterate backwards through channels + merged\n",
    "        for c in range(nChannels, -1, -1):\n",
    "            old_filename = f\"{FilePrefix}_S{s}_C{c}.mp4\"\n",
    "            new_filename = f\"Video-{counter}.mp4\"\n",
    "\n",
    "            old_filepath = subdir / old_filename\n",
    "            new_filepath = Path(OutputSubDir) / new_filename\n",
    "\n",
    "            if not old_filepath.exists():\n",
    "                print(f\"  Skipping missing file: {old_filepath.name}\")\n",
    "                continue\n",
    "\n",
    "            shutil.copy2(old_filepath, new_filepath)\n",
    "            counter += 1\n",
    "\n",
    "    print(\"Renamed videos saved in:\", OutputDir_Renamed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsi-img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
